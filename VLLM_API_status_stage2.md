# vLLM Responses API - –°—Ç–∞—Ç—É—Å —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ (Stage 2)

## –î–∞—Ç–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏: 2025-11-21

## –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | –í—Å–µ–≥–æ | –†–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ | –ß–∞—Å—Ç–∏—á–Ω–æ | –ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ |
|-----------|-------|-------------|----------|----------------|
| üî¥ Critical (C1-C4) | 4 | **4** | 0 | 0 |
| üü° High (H1-H5) | 5 | **5** | 0 | 0 |
| üü† Medium (M1-M6) | 6 | **6** | 0 | 0 |
| üü¢ Low (L1-L8) | 8 | **7** | 0 | 1 |
| ‚ö° Edge Cases (E1-E8) | 8 | **8** | 0 | 0 |
| üìñ Documentation (D1-D5) | 5 | **2** | 0 | 3 |
| ‚úÖ Testing (T1) | 1 | 0 | **1** | 0 |
| **–ò–¢–û–ì–û** | **37** | **32** | **1** | **4** |

**–ü—Ä–æ—Ü–µ–Ω—Ç –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è:** ~89% (33/37 –∑–∞–¥–∞—á)

---

## –°—Ä–∞–≤–Ω–µ–Ω–∏–µ Stage 1 vs Stage 2

| –ö–∞—Ç–µ–≥–æ—Ä–∏—è | Stage 1 | Stage 2 | –ò–∑–º–µ–Ω–µ–Ω–∏–µ |
|-----------|---------|---------|-----------|
| Critical | 3/4 (75%) | **4/4 (100%)** | +1 |
| High | 5/5 (100%) | **5/5 (100%)** | - |
| Medium | 4/6 (67%) | **6/6 (100%)** | +2 |
| Low | 3/8 (38%) | **7/8 (88%)** | +4 |
| Edge Cases | ? | **8/8 (100%)** | +8 |
| Documentation | 0/5 (0%) | **2/5 (40%)** | +2 |
| Testing | 0/1 (0%) | **1/1 partial** | +0.5 |

**–û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: 54% ‚Üí 89%** (+35%)

---

## Critical Priority Tasks (C1-C4) - 4/4 ‚úÖ

### C1: `/v1/responses/{id}/tool_outputs` endpoint
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/api_server.py:1176-1191`:
  ```python
  @router.post("/v1/responses/{response_id}/tool_outputs")
  async def submit_tool_outputs(...)
      result = await handler.submit_tool_outputs(response_id, payload)
  ```
- `vllm/entrypoints/openai/serving_responses.py:2034`:
  ```python
  async def submit_tool_outputs(self, response_id: str, request: ResponsesToolOutputsRequest)
  ```
- CLI –∞—Ä–≥—É–º–µ–Ω—Ç—ã: `--responses-tool-timeout` (cli_args.py:202)

---

### C2: `response.tool_call.delta` SSE event
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:2532-2538`:
  ```python
  class ResponseToolCallDeltaEvent(OpenAIBaseModel):
      """OpenAI-compatible response.tool_call.delta streaming event."""
      type: Literal["response.tool_call.delta"] = "response.tool_call.delta"
      delta: dict[str, list[ResponseToolCallDeltaContent]]
  ```
- `vllm/entrypoints/openai/serving_responses.py:634-645`:
  ```python
  def _build_tool_call_delta_event(...) -> ResponseToolCallDeltaEvent:
      """Create an OpenAI-compatible response.tool_call.delta event."""
  ```
- –í–∫–ª—é—á—ë–Ω –≤ SSE_ALLOWED_EVENTS (api_server.py:599)

---

### C3: Stateful Response Sessions
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/serving_responses.py:209-237`:
  ```python
  class ResponseSession:
      """Tracks state for a single streaming response."""
      response_id: str
      request: ResponsesRequest
      context: ConversationContext | None = None
      tool_output_event: asyncio.Event = field(default_factory=asyncio.Event)
      waiting_for_tool_outputs: bool = False
  ```
- `vllm/entrypoints/openai/serving_responses.py:239-310`:
  ```python
  class ResponseSessionManager:
      """Manages active streaming sessions with TTL and eviction."""
      def add_session(self, session: ResponseSession) -> None
      def get_session(self, session_id: str) -> ResponseSession | None
      def remove_session(self, session_id: str) -> ResponseSession | None
      def cleanup_expired_sessions(self) -> None
  ```
- –û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ —Å–µ—Å—Å–∏–π: `--responses-max-active-sessions` (cli_args.py:234)
- Eviction policy: `serving_responses.py:294-305`

---

### C4: `response.error` SSE event
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:2637-2647`:
  ```python
  class ResponseErrorEvent(OpenAIBaseModel):
      type: Literal["response.error"] = "response.error"
      response: dict
      error: ErrorInfo
      sequence_number: int
  ```
- `vllm/entrypoints/openai/serving_responses.py:1886-1904`:
  ```python
  def _build_error_event(...) -> ResponseErrorEvent:
      """Create a ResponseErrorEvent that continues the stream sequence."""
  ```
- –í–∫–ª—é—á—ë–Ω –≤ SSE_ALLOWED_EVENTS (api_server.py:610)

---

## High Priority Tasks (H1-H5) - 5/5 ‚úÖ

### H1: `prompt_cache_key` parameter
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:373`:
  ```python
  prompt_cache_key: str | None = Field(...)
  ```
- `vllm/entrypoints/openai/serving_responses.py:784-796`:
  ```python
  def _apply_prompt_cache_key(self, request: ResponsesRequest) -> None:
      """Map OpenAI's prompt_cache_key to the internal cache salt."""
  ```
- –í–∞–ª–∏–¥–∞—Ü–∏—è: `protocol.py:519-524`

---

### H2: Rename Reasoning Events to OpenAI Format
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:2543-2557`:
  ```python
  class ResponseReasoningDeltaEvent(OpenAIBaseModel):
      type: Literal["response.reasoning.delta"] = "response.reasoning.delta"
  ```
- `vllm/entrypoints/openai/serving_responses.py:593-594`:
  ```python
  return ResponseReasoningDeltaEvent(
      type="response.reasoning.delta",
  ```

---

### H3: `response.reasoning.summary.*` events
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:2579-2601`:
  ```python
  class ResponseReasoningSummaryDeltaEvent(OpenAIBaseModel):
      type: Literal["response.reasoning.summary.delta"] = "response.reasoning.summary.delta"

  class ResponseReasoningSummaryAddedEvent(OpenAIBaseModel):
      type: Literal["response.reasoning.summary.added"] = "response.reasoning.summary.added"
  ```
- `vllm/entrypoints/openai/serving_responses.py:313`:
  ```python
  class ReasoningSummaryExtractor:
      """Extracts concise summary from detailed reasoning output."""
  ```
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: `serving_responses.py:664-676`

---

### H4: `response.additional_context` event
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:2606-2625`:
  ```python
  class ResponseAdditionalContextEvent(OpenAIBaseModel):
      type: Literal["response.additional_context"] = "response.additional_context"
  ```
- `vllm/entrypoints/openai/reasoning_encryption.py:26`:
  ```python
  class ReasoningEncryption:
      """Encrypt/decrypt reasoning payloads for response.additional_context."""
  ```
- CLI: `--reasoning-encryption-key` (cli_args.py:187)
- –ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Å–æ–±—ã—Ç–∏–π: `serving_responses.py:739-755`

---

### H5: `response.rate_limits.updated` event
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:2628-2635`:
  ```python
  class ResponseRateLimitsUpdatedEvent(OpenAIBaseModel):
      type: Literal["response.rate_limits.updated"] = "response.rate_limits.updated"
  ```
- `vllm/entrypoints/openai/rate_limits.py:79`:
  ```python
  class RateLimitTracker:
      """Simple rate limit tracker for emitting rate_limits.updated events."""
  ```
- CLI –æ–ø—Ü–∏–∏: `--enable-rate-limit-events`, `--rate-limit-*` (cli_args.py:189-195)
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: `serving_responses.py:3351-3352`

---

## Medium Priority Tasks (M1-M6) - 6/6 ‚úÖ

### M1: Azure Endpoint Format Support
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/api_server.py:146-150`:
  ```python
  SUPPORTED_AZURE_API_VERSIONS = [
      "2024-02-15-preview",
      "2024-03-01-preview",
      "2024-05-01-preview",
  ]
  ```
- `vllm/entrypoints/openai/api_server.py:987-1061`:
  ```python
  @router.post("/openai/deployments/{deployment_name}/responses")
  async def create_responses_azure(...)
  ```
- Azure auth: `_azure_auth_dependency()` (api_server.py:950)
- Azure headers: `x-ms-region`, `x-ms-request-id`, `api-supported-versions`
- CLI: `--enable-azure-api`, `--azure-region`
- –ü—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ–µ `store=true` –¥–ª—è Azure (api_server.py:1037)

---

### M2: OpenAI-Compatible Error Types
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:134-157`:
  ```python
  class OpenAIErrorType(str, Enum):
      INVALID_API_KEY = "invalid_api_key"
      RATE_LIMIT_ERROR = "rate_limit_error"
      NOT_FOUND_ERROR = "not_found_error"
      QUOTA_EXCEEDED = "quota_exceeded"
      # ... –∏ –¥—Ä—É–≥–∏–µ
  ```
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ –≤ serving_models.py, serving_responses.py, serving_engine.py

---

### M3: Retry-After Header Handling
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/api_server.py:783-801`:
  ```python
  _DEFAULT_RETRY_AFTER_SECONDS = 1.0

  def _maybe_add_retry_after_header(
      response: Response,
      error: ErrorResponse,
      retry_after: float | None = None,
  ) -> None:
      ...
      response.headers.setdefault("Retry-After", str(max(1, math.ceil(seconds))))
  ```
- `vllm/entrypoints/openai/protocol.py:169`:
  ```python
  retry_after: float | None = None
  ```
- –ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: api_server.py:809, 888

---

### M4: All `include` Parameter Options
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:348-353`:
  ```python
  "code_interpreter_call.outputs",
  "file_search_call.results",
  "reasoning.encrypted_content",
  ```
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–∞–µ—Ç –ø–æ–¥–¥–µ—Ä–∂–∫—É: `computer_call_output.output.image_url` (—Å `--enable-computer-call`)

---

### M5: HTTP Headers Compatibility
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- X-Request-Id: `api_server.py:1978-2001`, `cli_args.py:145`
- OpenAI-Organization: `api_server.py:853-857`, `cli_args.py:221`
- x-ratelimit-* headers: `serving_responses.py:878-883`:
  ```python
  headers["x-ratelimit-limit-requests"] = str(req_stats["limit"])
  headers["x-ratelimit-remaining-requests"] = str(req_stats["remaining"])
  headers["x-ratelimit-limit-tokens"] = str(token_stats["limit"])
  headers["x-ratelimit-remaining-tokens"] = str(token_stats["remaining"])
  ```

---

### M6: `store` Parameter Semantics
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:369`:
  ```python
  store: bool | None = True
  ```
- CLI: `--responses-store-*` flags –¥–ª—è TTL/quotas

---

## Low Priority Tasks (L1-L8) - 7/8 ‚úÖ

### L1: Comprehensive SSE Validation
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/api_server.py:588-690`:
  ```python
  class SSEValidationError(Exception):
      """Raised when SSE event validation fails."""

  class SSEEventValidator:
      """Validates outgoing SSE events to prevent malformed streams."""

      def validate(self, event_type: str, sequence_number: int) -> None:
          if not event_type:
              raise SSEValidationError("Missing SSE event type.")
          if "\n" in event_type:
              raise SSEValidationError("SSE event type must not contain newlines.")
          # ... –∏ –¥—Ä—É–≥–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
  ```

---

### L2: Performance Optimization for Streaming
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- –ë—É—Ñ–µ—Ä–∏–∑–∞—Ü–∏—è SSE: `--responses-stream-buffer-max-bytes` (cli_args.py)
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: "Internally we buffer SSE payloads (~16 KB)"

---

### L3: Compatibility Mode Flag
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/cli_args.py:216`:
  ```python
  responses_compatibility_mode: bool = True
  ```
- `vllm/entrypoints/openai/serving_responses.py:401, 417`:
  ```python
  def __init__(self, ..., compatibility_mode: bool = False):
      self.compatibility_mode = compatibility_mode
  ```
- –í–∞–ª–∏–¥–∞—Ü–∏—è unsupported fields: `serving_responses.py:986-1012`

---

### L4: Ping/Keep-alive for SSE
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/serving_responses.py:402, 438`:
  ```python
  ping_interval_seconds: float = 15.0,
  ...
  self.ping_interval_seconds = max(0.0, float(ping_interval_seconds))
  ```
- CLI: `--responses-ping-interval-seconds`
- –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: "response.ping (keep-alive heartbeats)"

---

### L5: `[DONE]` Message in SSE Stream
**–°—Ç–∞—Ç—É—Å:** ‚ùå –ù–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù–û –¥–ª—è Responses API

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** `[DONE]` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ Chat Completions –∏ Completions API, –Ω–æ –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ serving_responses.py. OpenAI Responses API –º–æ–∂–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–æ–π –º–µ—Ö–∞–Ω–∏–∑–º –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è (response.completed event).

---

### L6: sequence_number Tracking
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/serving_responses.py:1889-1904`:
  ```python
  next_sequence_number = 0
  ...
  last_sequence = getattr(last_event, "sequence_number", None)
  if last_sequence is not None:
      next_sequence_number = last_sequence + 1
  ```
- –§—É–Ω–∫—Ü–∏—è `_increment_sequence_number_and_return()` –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ–≤—Å–µ–º–µ—Å—Ç–Ω–æ

---

### L7: Request/Response ID Consistency
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/serving_responses.py:1098, 3463`:
  ```python
  header_request_id = raw_request.headers.get("X-Request-Id")
  ...
  "Request ID mismatch: header X-Request-Id "
  ```

---

### L8: service_tier Parameter Behavior
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–¥–µ:**
- `vllm/entrypoints/openai/protocol.py:368`:
  ```python
  service_tier: Literal["auto", "default", "flex", "scale", "priority"] = "auto"
  ```
- CLI: `--responses-default-service-tier`, `--responses-allowed-service-tiers`

---

## Edge Cases & Validation (E1-E8) - 8/8 ‚úÖ

### E1: Handle Malformed SSE Gracefully
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

- `SSEValidationError` –∏ `SSEEventValidator` (api_server.py:588-639)

---

### E2: Timeout Handling for Tool Outputs
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

- `tool_outputs_timeout` parameter (serving_responses.py:385, 499)
- `--responses-tool-timeout` CLI (cli_args.py:202)
- TimeoutError handling (serving_responses.py:1986)

---

### E3: Concurrent Tool Calls Validation
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

- `parallel_tool_calls` parameter (protocol.py:364, 607)

---

### E4: Large Payload Handling (>1MB)
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

- `--responses-tool-outputs-max-bytes` (cli_args.py:229)
- `--responses-sse-event-max-bytes` (cli_args.py:231)
- Validation: serving_responses.py:2043-2050

---

### E5: Session Cleanup on Client Disconnect
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

- `handle_stream_disconnect()` (serving_responses.py:2299-2305)
- `cleanup_expired_sessions()` (serving_responses.py:275)
- `_build_stream_disconnect_handler()` (api_server.py:767-777)

---

### E6: Duplicate tool_output Submission
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

- `serving_responses.py:2085`:
  ```python
  "Duplicate tool_outputs for call_id %s (response %s)"
  ```

---

### E7: Invalid JSON in Tool Arguments
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

- `serving_responses.py:931-933`:
  ```python
  except json.JSONDecodeError as exc:
      "Invalid JSON arguments for tool %s: %s"
  ```

---

### E8: Memory Limits for Long Sessions
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

- `--responses-max-active-sessions` (cli_args.py:234)
- Session eviction: serving_responses.py:294-305
- Buffer limits: `--responses-stream-buffer-max-bytes`

---

## Documentation & Compliance (D1-D5) - 2/5 ‚úÖ

### D1: Complete API Documentation
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–§–∞–π–ª:** `docs/serving/responses_api.md`

**–°–æ–¥–µ—Ä–∂–∏—Ç:**
- –í—Å–µ endpoints —Å –æ–ø–∏—Å–∞–Ω–∏–µ–º
- Request model highlights
- Streaming events –ø–æ–ª–Ω—ã–π —Å–ø–∏—Å–æ–∫
- Tool calling workflow
- Include parameter options

---

### D2: Migration Guide for Existing Users
**–°—Ç–∞—Ç—É—Å:** ‚úÖ –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–§–∞–π–ª:** `docs/migration/responses_api_v2.md`

**–°–æ–¥–µ—Ä–∂–∏—Ç:**
- Breaking changes –∏ resolutions
- Feature parity checklist
- Recommended server flags
- Quick start guide

---

### D3: OpenAI Compatibility Documentation
**–°—Ç–∞—Ç—É—Å:** ‚ùå –ù–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è —á–∞—Å—Ç–∏—á–Ω–æ –µ—Å—Ç—å –≤ responses_api.md, –Ω–æ –Ω–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ –¥–æ–∫—É–º–µ–Ω—Ç–∞ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è.

---

### D4: Code Examples and Tutorials
**–°—Ç–∞—Ç—É—Å:** ‚ùå –ù–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ù–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ `examples/responses_api/`

---

### D5: Troubleshooting Guide
**–°—Ç–∞—Ç—É—Å:** ‚ùå –ù–ï –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–ü—Ä–∏–º–µ—á–∞–Ω–∏–µ:** –ß–∞—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –µ—Å—Ç—å –≤ migration guide, –Ω–æ –Ω–µ—Ç –æ—Ç–¥–µ–ª—å–Ω–æ–≥–æ troubleshooting.

---

## Testing (T1) - –ß–∞—Å—Ç–∏—á–Ω–æ ‚úÖ

### T1: Comprehensive Compliance Test Suite
**–°—Ç–∞—Ç—É—Å:** ‚ö†Ô∏è –ß–ê–°–¢–ò–ß–ù–û –†–ï–ê–õ–ò–ó–û–í–ê–ù–û

**–ù–∞–π–¥–µ–Ω–Ω—ã–µ —Ç–µ—Å—Ç—ã:**
- `tests/entrypoints/openai/test_serving_responses.py` - –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ–∞–π–ª —Ç–µ—Å—Ç–æ–≤

**–°–æ–¥–µ—Ä–∂–∏—Ç:**
- –ú–æ–∫–∏ –¥–ª—è OpenAIServingResponses
- –¢–µ—Å—Ç—ã ResponseSession, ResponseSessionManager
- –¢–µ—Å—Ç—ã tool outputs
- –¢–µ—Å—Ç—ã RateLimitTracker

**–ß—Ç–æ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç:**
- –û—Ç–¥–µ–ª—å–Ω—ã–π compliance test suite —Å –º–∞—Ä–∫–∏—Ä–æ–≤–∫–æ–π `@pytest.mark.compliance`
- –¢–µ—Å—Ç—ã –ø—Ä–∏–≤—è–∑–∞–Ω–Ω—ã–µ –∫ –Ω–æ–º–µ—Ä–∞–º —Å—Ç—Ä–æ–∫ —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏
- –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è `tests/compliance/`

---

## –†–µ–∑—é–º–µ

### –ü–æ–ª–Ω–æ—Å—Ç—å—é —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (32 –∑–∞–¥–∞—á–∏):
- **Critical:** C1, C2, C3, C4 (4/4)
- **High:** H1, H2, H3, H4, H5 (5/5)
- **Medium:** M1, M2, M3, M4, M5, M6 (6/6)
- **Low:** L1, L2, L3, L4, L6, L7, L8 (7/8)
- **Edge Cases:** E1, E2, E3, E4, E5, E6, E7, E8 (8/8)
- **Documentation:** D1, D2 (2/5)

### –ß–∞—Å—Ç–∏—á–Ω–æ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (1 –∑–∞–¥–∞—á–∞):
- T1: –¢–µ—Å—Ç—ã –µ—Å—Ç—å, –Ω–æ –Ω–µ compliance suite

### –ù–µ —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ (4 –∑–∞–¥–∞—á–∏):
- L5: `[DONE]` message
- D3: OpenAI compatibility doc
- D4: Code examples
- D5: Troubleshooting guide

---

## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—é

### –í—ã—Å–æ–∫–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
1. **L5 `[DONE]` message** - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, –Ω—É–∂–µ–Ω –ª–∏ –¥–ª—è Responses API (–º–æ–∂–µ—Ç –Ω–µ —Ç—Ä–µ–±–æ–≤–∞—Ç—å—Å—è, —Ç.–∫. –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è response.completed)

### –°—Ä–µ–¥–Ω–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç:
2. **D3-D5 Documentation** - –¥–æ–ø–æ–ª–Ω–∏—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é
3. **T1 Compliance tests** - —Å–æ–∑–¥–∞—Ç—å compliance test suite

---

## –ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–π–ª—ã —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏

| –§–∞–π–ª | –ó–∞–¥–∞—á–∏ | –°—Ç—Ä–æ–∫ –∫–æ–¥–∞ |
|------|--------|------------|
| `vllm/entrypoints/openai/serving_responses.py` | C1-C4, H1-H5, L1-L8, E1-E8 | ~3500 |
| `vllm/entrypoints/openai/protocol.py` | –í—Å–µ –º–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö | ~2700 |
| `vllm/entrypoints/openai/api_server.py` | C1, M1, M3, M5, E1, E5 | ~2400 |
| `vllm/entrypoints/openai/rate_limits.py` | H5 | ~100 |
| `vllm/entrypoints/openai/reasoning_encryption.py` | H4 | ~80 |
| `vllm/entrypoints/openai/cli_args.py` | –í—Å–µ CLI –æ–ø—Ü–∏–∏ | ~250 |
| `docs/serving/responses_api.md` | D1 | ~100 |
| `docs/migration/responses_api_v2.md` | D2 | ~80 |

---

## –ò—Ç–æ–≥–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞

**Stage 2 –ø–æ–∫–∞–∑—ã–≤–∞–µ—Ç –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ–≥—Ä–µ—Å—Å:**

- **89% –∑–∞–¥–∞—á —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ** (vs 54% –≤ Stage 1)
- **–í—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –∏ –≤—ã—Å–æ–∫–æ–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –∑–∞–¥–∞—á–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã** (100%)
- **–í—Å–µ medium priority –∑–∞–¥–∞—á–∏ –∑–∞–≤–µ—Ä—à–µ–Ω—ã** (100%)
- **–í—Å–µ edge cases –æ–±—Ä–∞–±–æ—Ç–∞–Ω—ã** (100%)
- **–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è —á–∞—Å—Ç–∏—á–Ω–æ –≥–æ—Ç–æ–≤–∞** (40%)

**vLLM Responses API –≥–æ—Ç–æ–≤ –∫ production –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é** —Å —Ç–µ–∫—É—â–∏–º —É—Ä–æ–≤–Ω–µ–º —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏.
