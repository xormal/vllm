# Руководство по `/compact`

Команда `/compact` запускает встроенную процедуру сжатия истории (compaction). Её цель — пересобрать контекст беседы в более короткий вид, чтобы не упереться в лимиты токенов. Сжатие может запускаться вручную (через команду) и автоматически (после завершения очередного шага, если токены закончились). Ниже — все связанные настройки и точный алгоритм.

---

## 1. Где доступна команда

| Клиент | Как вызвать | Что происходит внутри |
| ------ | ----------- | ---------------------- |
| TUI | Введите `/compact` (см. `tui/src/slash_command.rs:20-70`). | Отправляется `Op::Compact` в ядро (`core/src/protocol.rs:174-183`), которое берёт текущий `TurnContext` и инициирует задачу `CompactTask`. |
| CLI | В интерактивном REPL команда `compact` тоже приводит к `Op::Compact` (тот же обработчик). |
| Telegram | Пока не реализовано как slash-команда (нужно отправлять обычное сообщение Codex CLI). |

В обоих случаях обработчик (`core/src/codex.rs:1577-1595`) сначала пытается **впрыснуть** компактирующий запрос в уже работающую задачу (`sess.inject_input`). Если активной задачи нет или она не принимает вход, Codex создаёт отдельный `CompactTask` (`core/src/tasks/compact.rs:15-30`), который выполняет ту же процедуру, что и автокомпакт.

---

## 2. Настройки

### 2.1 Порог автокомпакта

`model_auto_compact_token_limit` (`core/src/config/mod.rs:105-118`):

```toml
# ~/.codex/config.toml
model_auto_compact_token_limit = 180000   # пример
```

- Если параметр не задан, Codex берёт значение из модели (`core/src/openai_model_info.rs:12-53`). По умолчанию это 90% от контекстного окна (`context_window * 0.9`).
- Установите более низкий порог, если хотите, чтобы авто-сжатие запускалось раньше. Чтобы фактически отключить автоматический запуск, выставьте очень большое число (например, `9_999_999`) или `null`.

Получение лимита выполняется через `ModelClient::get_auto_compact_token_limit()` (`core/src/client.rs:129-135`).

### 2.2 Промпт суммаризации

1. **По умолчанию** используется `core/templates/compact/prompt.md` (доступен через `SUMMARIZATION_PROMPT` в `core/src/codex/compact.rs:24`).
2. **Конфиг**: можете задать строку в `compact_prompt`:
   ```toml
   compact_prompt = """
   Сформируй краткую сводку беседы в виде ...
   """
   ```
3. **Файл**: `experimental_compact_prompt_file = "/path/to/prompt.txt"` позволяет держать шаблон вне TOML. При загрузке (`core/src/config/mod.rs:1118-1159`) порядок приоритетов такой:
   1. CLI/профильные overrides (если заданы).
   2. `compact_prompt` из текущего профиля/корневого `config.toml`.
   3. `experimental_compact_prompt_file`.
   4. Шаблон по умолчанию.

Во всех случаях `TurnContext::compact_prompt()` (`core/src/codex.rs:287-306`) возвращает итоговую строку, которую получит модель во время compact-задачи.

### 2.3 Ограничение на объём истории пользователя

- `COMPACT_USER_MESSAGE_MAX_TOKENS = 20_000` (`core/src/codex/compact.rs:23`) — размер, в пределах которого сохраняются последние сообщения пользователя при пересборке истории. Фактически лимит пересчитывается в байты (`* 4`, см. `build_compacted_history_with_limit`), так что слишком длинные сообщения будут усечены через `truncate_middle`.

---

## 3. Ручной запуск (`/compact`)

1. По команде Codex пытается вставить в текущий активный turn пользовательский ввод, содержащий `compact_prompt`. Это позволяет переиспользовать уже открытое соединение с моделью.
2. Если вставка не удалась (например, нет активного запроса), запускется `CompactTask` в отдельном turn (`core/src/tasks/compact.rs:18-30`).  
3. Пользователь увидит три события:
   - `TaskStarted` (информационное сообщение в UI).
   - `AgentMessage("Compact task completed")`.
   - `Warning("Heads up: Long conversations ...")` — напоминание начать новую беседу, если компактов уже много.

---

## 4. Автоматическое срабатывание

Каждый пользовательский turn завершается в `run_turn` (`core/src/codex.rs:1784-1870`). После обработки инструмента Codex делает следующее:

1. Получает `total_token_usage` от модели (сумма вход + выход).
2. Сравнивает с `limit = get_auto_compact_token_limit()`.
3. Если `tokens >= limit` и компактизатор ещё не запускался в этом turn, устанавливается флаг `auto_compact_recently_attempted` и вызывается `run_inline_auto_compact_task()` (`core/src/codex/compact.rs:31-37`).
4. Compact выполняется синхронно, история пересобирается, и тот же turn повторяется заново уже с укороченным контекстом.
5. Если при следующем измерении токены всё ещё превышают лимит, Codex отправляет пользователю ошибку:
   ```
   Conversation is still above the token limit after automatic summarization (limit …).
   ```
   и предлагает начать новую сессию либо вручную обрезать историю.

Таким образом, автоматика пытается спасти переполненный контекст один раз; повторный запуск в пределах того же turn не делается, чтобы не тратить лишние запросы.

---

## 5. Что именно делает компактор

Алгоритм описан в `core/src/codex/compact.rs:40-190`:

1. **Сбор истории**. Codex клонирует историю (`sess.clone_history()`) и добавляет промпт компакта как `ResponseInputItem`.
2. **Подготовка**. Если история не помещается в контекст модели, старые элементы по одному отбрасываются (логируются через `error!` + `notify_background_event`).
3. **Запрос к LLM**. Через `drain_to_completed` (`core/src/codex/compact.rs:227-274`) Codex отправляет промпт и ждёт, пока поток событий выдаст `response.completed`. Все `OutputItemDone` (включая сообщения модели) добавляются обратно в историю.
4. **Извлечение результата**:
   - `summary_text` — последняя ассистентская реплика (обычно содержимое суммаризации).
   - `user_messages` — список пользовательских сообщений из истории (собирается через `TurnItem::UserMessage`, `collect_user_messages`).
5. **Пересборка** (`build_compacted_history`):
   - В начало ставятся неизменяемые элементы: системные инструкции, developer-инструкции, GhostSnapshots и т.д. (см. `initial_context`).
   - Добавляются последние пользовательские сообщения (усечённые до лимита).
   - В конец всегда добавляется пользовательский `Message` с текстом `summary_text`. Этот приём помогает модели воспринимать итог как «знание о предыдущем диалоге».
6. **Сохранение**. Новая история заменяет старую (`sess.replace_history`). В rollout записывается событие `RolloutItem::Compacted` (`core/src/codex.rs:2884-2925`), что видно в `/rollout`.
7. **Сигналы UI**. Отправляется `AgentMessage("Compact task completed")` и предупреждение о деградации качества.

Важные детали:

- Ghost snapshots (`ResponseItem::GhostSnapshot`) и другие служебные элементы сохраняются.
- Если compaction запущена вручную и пользователь дополнил промпт своими инструкциями (например, попросил «оставь больше деталей про шаги X»), эти инструкции будут частью user_input, влияя на summary_text.

---

## 6. Практические советы

1. **Настройте порог под модель.** Для больших моделей (GPT-5) ограничение 90% от 272k ≈ 244k токенов, но если вы часто используете длинные diff’ы, лучше снизить до, скажем, 200k, чтобы компактор успевал до ошибки.
2. **Делайте кастомный промпт.** Если нужно, чтобы summary имел конкретный формат (например, список задач + таблица), задайте `compact_prompt` в `config.toml` или подключите файл. Не забудьте описать, какие блоки истории нужно сохранить.
3. **Следите за предупреждениями.** После каждого компакта выводится предупреждение — это знак, что история уже переписывалась и ответы могут быть менее точными. Точка отсчёта — `RolloutItem::Compacted` в `/rollout` или статус во вкладке истории.
4. **Не злоупотребляйте.** Компактор — это отдельный вызов модели. Если запускать его после каждого шага вручную, вы будете дополнительно расходовать токены.
5. **При автокомпакте ошибки нельзя игнорировать.** Если после автоматического сжатия лимит всё равно превышен, единственный способ — начать новую сессию или руками удалить лишние сообщения (`/clear` / `/reset`).

Теперь вы знаете, как управлять `/compact`, какие настройки влияют на алгоритм и что происходит под капотом при автоматическом сжатии контекста.
